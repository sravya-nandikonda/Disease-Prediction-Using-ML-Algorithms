{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a786444",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13841cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"breat_cancer_prediction_dataSet.csv\") #this is a dataframe\n",
    "#df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "14ee4b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count of empty values present in each col\n",
    "#df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0768167d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(axis=1, how='all', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3399548f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6bd5faba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['diagnosis'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7db7476b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sns.countplot(df['diagnosis'],label='count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "54b63081",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode the categorial data values\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "labelencoder_Y = LabelEncoder()\n",
    "df.iloc[:,1]=labelencoder_Y.fit_transform(df.iloc[:,1].values) #importing values from all the rows of col 2 ie index 1\n",
    "# M are presented as 1 and B as 0\n",
    "#df.iloc[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "abb60ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "441488c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlation of columns\n",
    "#df.iloc[:,1:12].corr() \n",
    "# +ve value indicate positive influence and -ve indicates negative influence and 0 indicates no influence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fbc8e711",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualization of correlation\n",
    "#plt.figure(figsize=(10,10))\n",
    "#sns.heatmap(df.iloc[:,1:12].corr(), annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a341a007",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:,2:32].values\n",
    "Y = df.iloc[:,1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "651ad27f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X)\n",
    "standardized_data = scaler.transform(X)\n",
    "#print(standardized_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "76d1b45f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 75% training and 25% training\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size=0.25, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "792ef0ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.fit_transform(X_test)\n",
    "#X_test.shape\n",
    "#X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4acaff8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(criterion='entropy', random_state=0)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create a function for the models\n",
    "#def models(X_train, Y_train):\n",
    "\n",
    "#logistic regression\n",
    "#from sklearn.linear_model import LogisticRegression\n",
    "#log = LogisticRegression(random_state=0)\n",
    "#log.fit(X_train, Y_train)\n",
    "\n",
    "#decision tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "tree = DecisionTreeClassifier(criterion='entropy', random_state=0)\n",
    "tree.fit(X_train, Y_train)\n",
    "\n",
    "#random forest classifier\n",
    "#from sklearn.ensemble import RandomForestClassifier\n",
    "#forest = RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state=0)\n",
    "#forest.fit(X_train, Y_train)\n",
    "\n",
    "  #print('Logistic Regression Training Accuracy: ', log.score(X_train, Y_train))\n",
    "#print('Decision Tree Classifier Training Accuracy: ', tree.score(X_train, Y_train))\n",
    "  #print('Random Forest Classifier Training Accuracy: ', forest.score(X_train, Y_train))\n",
    "\n",
    "#  return  forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f50f77dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = models(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "340b4242",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test model accuracy on test data on confusion matrix\n",
    "\n",
    "#model_name = ['Decision Tree']\n",
    "\n",
    "#test model accuracy on test data on confusion matrix\n",
    "#model_name = ['Logistic Regression','Decision Tree','Random Forest']\n",
    "#from sklearn.metrics import confusion_matrix\n",
    "\n",
    "#print(confusion_matrix(Y_test,Y_train))\n",
    "#sns.heatmap(confusion_matrix(Y_test,Y_train),annot=True)\n",
    "#print(model_name[0])\n",
    "#cm = confusion_matrix(Y_test, X_test)\n",
    " # print(cm)\n",
    "\n",
    "#  TP = cm[0][0]\n",
    " # TN = cm[1][1]\n",
    "  #FN = cm[0][1]test,Y_pred),annot=True)\n",
    "#for i in range(len(model_name)):\n",
    "#print('Model ')\n",
    "  #FP = cm[1][0]\n",
    "\n",
    "#  print(\"testing acuuracy: \",(TP+TN)/(TP+TN+FN+FP))\n",
    "#  print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d47bdf7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# printing the prediction fo random forest classifier model\n",
    "#pred = model[2].predict(X_test)\n",
    "#print(pred)\n",
    "#print()\n",
    "#print(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "467d4c25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enter input:\n",
      "enter radius mean:17.99\n",
      "enter texture mean:10.38\n",
      "enter perimeter mean:122.8\n",
      "enter area mean:1001\n",
      "enter smoothness mean:0.1184\n",
      "enter compactness mean:0.2776\n",
      "enter concavity mean:0.3001\n",
      "enter concave points mean:0.1471\n",
      "enter symmetry mean:0.2419\n",
      "enter fractal dimension mean:0.07871\n",
      "enter radius standard error :1.095\n",
      "enter texture standard error :0.9053\n",
      "enter perimeter standard error :8.589\n",
      "enter area standard error :153.4\n",
      "enter smoothness standard error :0.006399\n",
      "enter compactness standard error:0.0494904\n",
      "enter concavity standard error:0.5373\n",
      "enter concave points standard error:0.01587\n",
      "enter symmetry standard error:0.03003\n",
      "enter fractal dimension standard error:0.006193\n",
      "enter radius worst:25.38\n",
      "enter texture worst:17.33\n",
      "enter perimeter worst:184.6\n",
      "enter area worst:2019\n",
      "enter smoothness worst:0.1622\n",
      "enter compactness worst:0.6656\n",
      "enter concavity worst:0.7119\n",
      "enter concave points worst:0.2654\n",
      "enter symmetry worst:0.4601\n",
      "enter fractal dimension worst:0.1189\n",
      "Malignant\n"
     ]
    }
   ],
   "source": [
    "def predict():\n",
    "    print(\"enter input:\")\n",
    "\n",
    "    lst=[]\n",
    "    #for i in range(2,31):\n",
    "    r=float(input(\"enter radius mean:\"))\n",
    "    lst.append([r])\n",
    "    r=float(input(\"enter texture mean:\"))\n",
    "    lst.append([r])\n",
    "    r=float(input(\"enter perimeter mean:\"))\n",
    "    lst.append([r])\n",
    "    r=float(input(\"enter area mean:\"))\n",
    "    lst.append([r])\n",
    "    r=float(input(\"enter smoothness mean:\"))\n",
    "    lst.append([r])\n",
    "    r=float(input(\"enter compactness mean:\"))\n",
    "    lst.append([r])\n",
    "    r=float(input(\"enter concavity mean:\"))\n",
    "    lst.append([r])\n",
    "    r=float(input(\"enter concave points mean:\"))\n",
    "    lst.append([r])\n",
    "    r=float(input(\"enter symmetry mean:\"))\n",
    "    lst.append([r])\n",
    "    r=float(input(\"enter fractal dimension mean:\"))\n",
    "    lst.append([r])\n",
    "    r=float(input(\"enter radius standard error :\"))\n",
    "    lst.append([r])\n",
    "    r=float(input(\"enter texture standard error :\"))\n",
    "    lst.append([r])\n",
    "    r=float(input(\"enter perimeter standard error :\"))\n",
    "    lst.append([r])\n",
    "    r=float(input(\"enter area standard error :\"))\n",
    "    lst.append([r])\n",
    "    r=float(input(\"enter smoothness standard error :\"))\n",
    "    lst.append([r])\n",
    "    r=float(input(\"enter compactness standard error:\"))\n",
    "    lst.append([r])\n",
    "    r=float(input(\"enter concavity standard error:\"))\n",
    "    lst.append([r])\n",
    "    r=float(input(\"enter concave points standard error:\"))\n",
    "    lst.append([r])\n",
    "    r=float(input(\"enter symmetry standard error:\"))\n",
    "    lst.append([r])\n",
    "    r=float(input(\"enter fractal dimension standard error:\"))\n",
    "    lst.append([r])\n",
    "    r=float(input(\"enter radius worst:\"))\n",
    "    lst.append([r])\n",
    "    r=float(input(\"enter texture worst:\"))\n",
    "    lst.append([r])\n",
    "    r=float(input(\"enter perimeter worst:\"))\n",
    "    lst.append([r])\n",
    "    r=float(input(\"enter area worst:\"))\n",
    "    lst.append([r])\n",
    "    r=float(input(\"enter smoothness worst:\"))\n",
    "    lst.append([r])\n",
    "    r=float(input(\"enter compactness worst:\"))\n",
    "    lst.append([r])\n",
    "    r=float(input(\"enter concavity worst:\"))\n",
    "    lst.append([r])\n",
    "    r=float(input(\"enter concave points worst:\"))\n",
    "    lst.append([r])\n",
    "    r=float(input(\"enter symmetry worst:\"))\n",
    "    lst.append([r])\n",
    "    r=float(input(\"enter fractal dimension worst:\"))\n",
    "    lst.append([r])\n",
    "\n",
    "#input = (5,166,72,19,175,25.8,0.587,51)\n",
    "\n",
    "# Changing input data to numpy array\n",
    "    input_array = np.asarray(lst)\n",
    "\n",
    "# Reshaping input\n",
    "    input_reshaped = input_array.reshape(1,-1)\n",
    "\n",
    "# Standardiaing data\n",
    "    std_data = scaler.transform(input_reshaped)\n",
    "    #print(std_data)\n",
    "\n",
    "    prediction = tree.predict(std_data)\n",
    "    #print(prediction)\n",
    "\n",
    "    if(prediction[0]==0):\n",
    "        print('benign')\n",
    "    else:\n",
    "        print('Malignant')\n",
    "    \n",
    "predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e186558",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
